{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:17:24.192752: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 22:17:24.314655: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:17:24.314668: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-24 22:17:24.336051: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-24 22:17:24.931879: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:17:24.931926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:17:24.931932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classnames = [\"T_shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "\n",
    "classnames[y_train[0]]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[3])\n",
    "print(classnames[y_train[3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 454,230\n",
      "Trainable params: 454,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 22:17:34.208005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-24 22:17:34.208314: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-24 22:17:34.208350: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dauphongtantan): /proc/driver/nvidia/version does not exist\n",
      "2022-10-24 22:17:34.209045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten(input_shape=[28,28]))\n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dense(100,activation=\"relu\"))\n",
    "model.add(layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"rmsprop\",loss = \"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= x_train.astype(\"float32\")/255\n",
    "x_test= x_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.00392157 0.\n",
      "  0.         0.         0.         0.08627451 0.34509805 0.7372549\n",
      "  0.6745098  0.5176471  0.49019608 0.5529412  0.78039217 0.56078434\n",
      "  0.03529412 0.         0.         0.         0.00392157 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00392157 0.         0.\n",
      "  0.07843138 0.5137255  0.78039217 0.80784315 0.76862746 0.7921569\n",
      "  0.9490196  1.         1.         0.98039216 0.87058824 0.77254903\n",
      "  0.80784315 0.7372549  0.49411765 0.06666667 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00392157 0.         0.13725491\n",
      "  0.8392157  0.7490196  0.7176471  0.69803923 0.6862745  0.65882355\n",
      "  0.5882353  0.63529414 0.62352943 0.59607846 0.61960787 0.7019608\n",
      "  0.7176471  0.7411765  0.7647059  0.7254902  0.32156864 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.6666667\n",
      "  0.74509805 0.6745098  0.69411767 0.6901961  0.67058825 0.6627451\n",
      "  0.63529414 0.60784316 0.5803922  0.6039216  0.6627451  0.68235296\n",
      "  0.6862745  0.6862745  0.69411767 0.7176471  0.7372549  0.04705882\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.09803922 0.7607843\n",
      "  0.7058824  0.69803923 0.68235296 0.72156864 0.73333335 0.7411765\n",
      "  0.73333335 0.72156864 0.70980394 0.7411765  0.78431374 0.77254903\n",
      "  0.75686276 0.74509805 0.69803923 0.6862745  0.7607843  0.3529412\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.16470589 0.85490197\n",
      "  0.7490196  0.77254903 0.8156863  0.8        0.827451   0.81960785\n",
      "  0.8235294  0.83137256 0.827451   0.8392157  0.84313726 0.8352941\n",
      "  0.8392157  0.827451   0.827451   0.7490196  0.78431374 0.61960787\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.34509805 0.8666667\n",
      "  0.84313726 0.8509804  0.85882354 0.827451   0.7254902  0.5882353\n",
      "  0.4627451  0.41960785 0.3882353  0.34509805 0.3254902  0.3529412\n",
      "  0.5294118  0.83137256 0.79607844 0.8117647  0.85882354 0.6627451\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.10588235\n",
      "  0.4627451  0.63529414 0.15686275 0.         0.         0.\n",
      "  0.03921569 0.07450981 0.10980392 0.15294118 0.18431373 0.14117648\n",
      "  0.         0.         0.79607844 0.9019608  0.8627451  0.79607844\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5411765  0.53333336\n",
      "  0.2784314  0.27058825 0.21176471 0.84705883 0.8509804  0.79607844\n",
      "  0.72156864 0.65882355 0.6392157  0.63529414 0.6392157  0.69803923\n",
      "  0.8666667  0.7294118  0.14901961 0.10196079 0.02745098 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2627451  0.5254902\n",
      "  0.6039216  0.8784314  0.5058824  0.25882354 0.31764707 0.45882353\n",
      "  0.5058824  0.5019608  0.5176471  0.5372549  0.5137255  0.5058824\n",
      "  0.3372549  0.28627452 0.6156863  0.5921569  0.5254902  0.84705883\n",
      "  0.07058824 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.79607844 0.7764706\n",
      "  0.6745098  0.7176471  0.80784315 1.         1.         0.98039216\n",
      "  0.9529412  0.9411765  0.9372549  0.92156863 0.93333334 0.95686275\n",
      "  1.         0.93333334 0.72156864 0.627451   0.3372549  0.38431373\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.47843137 0.7372549\n",
      "  0.8784314  0.5921569  0.4117647  0.49803922 0.38039216 0.39215687\n",
      "  0.4117647  0.44705883 0.45882353 0.45882353 0.44313726 0.40392157\n",
      "  0.38431373 0.43529412 0.5568628  0.99607843 0.7490196  1.\n",
      "  0.19215687 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.6392157  0.7019608\n",
      "  0.78431374 0.37254903 0.6039216  0.7764706  0.77254903 0.78431374\n",
      "  0.78431374 0.7764706  0.77254903 0.7764706  0.78039217 0.7921569\n",
      "  0.78431374 0.6901961  0.3372549  0.80784315 0.6156863  0.63529414\n",
      "  0.03921569 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.77254903 0.7882353\n",
      "  0.8980392  0.2784314  0.5647059  0.7607843  0.70980394 0.7176471\n",
      "  0.7019608  0.7137255  0.7058824  0.7019608  0.7058824  0.74509805\n",
      "  0.7254902  0.77254903 0.29803923 0.85882354 0.7254902  0.7882353\n",
      "  0.13333334 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78039217 0.75686276\n",
      "  0.8862745  0.22745098 0.6039216  0.7529412  0.72156864 0.73333335\n",
      "  0.72156864 0.7294118  0.72156864 0.7254902  0.7176471  0.7529412\n",
      "  0.7490196  0.78431374 0.21960784 0.85882354 0.79607844 0.8117647\n",
      "  0.23529412 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.7882353  0.7607843\n",
      "  0.8784314  0.16078432 0.6392157  0.74509805 0.7294118  0.7294118\n",
      "  0.72156864 0.7254902  0.7176471  0.7254902  0.69803923 0.74509805\n",
      "  0.7607843  0.7921569  0.12941177 0.827451   0.78431374 0.80784315\n",
      "  0.28627452 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.7882353  0.77254903\n",
      "  0.87058824 0.06666667 0.6745098  0.74509805 0.7294118  0.73333335\n",
      "  0.7137255  0.7294118  0.7254902  0.73333335 0.7058824  0.73333335\n",
      "  0.75686276 0.7921569  0.10196079 0.83137256 0.7921569  0.79607844\n",
      "  0.29803923 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78431374 0.77254903\n",
      "  0.8745098  0.         0.69411767 0.7411765  0.72156864 0.7254902\n",
      "  0.69803923 0.72156864 0.7176471  0.72156864 0.7058824  0.7176471\n",
      "  0.7411765  0.79607844 0.13725491 0.76862746 0.79607844 0.79607844\n",
      "  0.32941177 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.78431374 0.77254903\n",
      "  0.8745098  0.         0.7254902  0.73333335 0.7254902  0.73333335\n",
      "  0.7058824  0.72156864 0.7137255  0.7176471  0.69803923 0.7137255\n",
      "  0.7176471  0.8039216  0.17254902 0.62352943 0.8117647  0.7882353\n",
      "  0.33333334 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.73333335 0.7764706\n",
      "  0.88235295 0.         0.7607843  0.7372549  0.72156864 0.7254902\n",
      "  0.7058824  0.7176471  0.7176471  0.72156864 0.70980394 0.70980394\n",
      "  0.69411767 0.80784315 0.18039216 0.5058824  0.827451   0.78431374\n",
      "  0.34509805 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.02352941 0.7294118  0.78431374\n",
      "  0.827451   0.         0.78039217 0.7411765  0.72156864 0.72156864\n",
      "  0.7254902  0.7137255  0.7176471  0.72156864 0.7254902  0.7137255\n",
      "  0.6862745  0.8039216  0.19607843 0.38039216 0.84705883 0.77254903\n",
      "  0.3647059  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.01960784 0.7254902  0.8\n",
      "  0.72156864 0.         0.7921569  0.7372549  0.7137255  0.7137255\n",
      "  0.7176471  0.7176471  0.72156864 0.7137255  0.7058824  0.7137255\n",
      "  0.68235296 0.7921569  0.24705882 0.23137255 0.8627451  0.76862746\n",
      "  0.36862746 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.01960784 0.72156864 0.80784315\n",
      "  0.6156863  0.         0.8        0.73333335 0.73333335 0.7411765\n",
      "  0.7529412  0.74509805 0.74509805 0.7490196  0.74509805 0.73333335\n",
      "  0.7176471  0.7921569  0.30588236 0.13725491 0.87058824 0.77254903\n",
      "  0.37254903 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.01960784 0.7176471  0.8156863\n",
      "  0.49803922 0.         0.77254903 0.6509804  0.6        0.58431375\n",
      "  0.58431375 0.57254905 0.5803922  0.58431375 0.5882353  0.5921569\n",
      "  0.61960787 0.7490196  0.3529412  0.03137255 0.8745098  0.7647059\n",
      "  0.3882353  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.02352941 0.72156864 0.8156863\n",
      "  0.44705883 0.         0.8        0.6784314  0.6313726  0.7058824\n",
      "  0.6901961  0.6745098  0.6784314  0.6784314  0.68235296 0.6901961\n",
      "  0.63529414 0.7921569  0.4509804  0.         0.8980392  0.78039217\n",
      "  0.4117647  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.03529412 0.69803923 0.8\n",
      "  0.4509804  0.         0.4745098  0.5294118  0.44705883 0.45882353\n",
      "  0.44705883 0.44705883 0.45882353 0.4627451  0.46666667 0.45882353\n",
      "  0.44313726 0.5764706  0.24705882 0.         0.88235295 0.76862746\n",
      "  0.41960785 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.07058824 0.7058824  0.80784315\n",
      "  0.5137255  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.8784314  0.77254903\n",
      "  0.48235294 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.5529412  0.5921569\n",
      "  0.29803923 0.         0.00392157 0.00392157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52156866 0.654902\n",
      "  0.28627452 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.5499 - accuracy: 0.8005 - val_loss: 0.4504 - val_accuracy: 0.8354\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3805 - accuracy: 0.8587 - val_loss: 0.3958 - val_accuracy: 0.8604\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3368 - accuracy: 0.8760 - val_loss: 0.4212 - val_accuracy: 0.8404\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3110 - accuracy: 0.8839 - val_loss: 0.3815 - val_accuracy: 0.8671\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2929 - accuracy: 0.8906 - val_loss: 0.4706 - val_accuracy: 0.8321\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2784 - accuracy: 0.8964 - val_loss: 0.4049 - val_accuracy: 0.8623\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2683 - accuracy: 0.9002 - val_loss: 0.3461 - val_accuracy: 0.8813\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2555 - accuracy: 0.9042 - val_loss: 0.3429 - val_accuracy: 0.8870\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2447 - accuracy: 0.9083 - val_loss: 0.3884 - val_accuracy: 0.8828\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2396 - accuracy: 0.9106 - val_loss: 0.3922 - val_accuracy: 0.8776\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2280 - accuracy: 0.9146 - val_loss: 0.3604 - val_accuracy: 0.8896\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2239 - accuracy: 0.9166 - val_loss: 0.3820 - val_accuracy: 0.8840\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2183 - accuracy: 0.9187 - val_loss: 0.3683 - val_accuracy: 0.8866\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2122 - accuracy: 0.9210 - val_loss: 0.3926 - val_accuracy: 0.8896\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2083 - accuracy: 0.9229 - val_loss: 0.4034 - val_accuracy: 0.8852\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2003 - accuracy: 0.9235 - val_loss: 0.3958 - val_accuracy: 0.8923\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1979 - accuracy: 0.9266 - val_loss: 0.4398 - val_accuracy: 0.8760\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1954 - accuracy: 0.9269 - val_loss: 0.4071 - val_accuracy: 0.8928\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1858 - accuracy: 0.9291 - val_loss: 0.4613 - val_accuracy: 0.8878\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1858 - accuracy: 0.9311 - val_loss: 0.5241 - val_accuracy: 0.8772\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1815 - accuracy: 0.9319 - val_loss: 0.5158 - val_accuracy: 0.8720\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1777 - accuracy: 0.9324 - val_loss: 0.5176 - val_accuracy: 0.8793\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1729 - accuracy: 0.9359 - val_loss: 0.4944 - val_accuracy: 0.8836\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1726 - accuracy: 0.9347 - val_loss: 0.4693 - val_accuracy: 0.8939\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1676 - accuracy: 0.9376 - val_loss: 0.5225 - val_accuracy: 0.8930\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1672 - accuracy: 0.9383 - val_loss: 0.4834 - val_accuracy: 0.8928\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1637 - accuracy: 0.9405 - val_loss: 0.6040 - val_accuracy: 0.8816\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1608 - accuracy: 0.9405 - val_loss: 0.5610 - val_accuracy: 0.8911\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1581 - accuracy: 0.9411 - val_loss: 0.5607 - val_accuracy: 0.8892\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1598 - accuracy: 0.9423 - val_loss: 0.6002 - val_accuracy: 0.8940\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1530 - accuracy: 0.9427 - val_loss: 0.6067 - val_accuracy: 0.8953\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1483 - accuracy: 0.9452 - val_loss: 0.6579 - val_accuracy: 0.8846\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1515 - accuracy: 0.9451 - val_loss: 0.7926 - val_accuracy: 0.8770\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1490 - accuracy: 0.9446 - val_loss: 0.6667 - val_accuracy: 0.8780\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1442 - accuracy: 0.9470 - val_loss: 0.7039 - val_accuracy: 0.8908\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1439 - accuracy: 0.9471 - val_loss: 0.6173 - val_accuracy: 0.8887\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1433 - accuracy: 0.9471 - val_loss: 0.6496 - val_accuracy: 0.8884\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1400 - accuracy: 0.9484 - val_loss: 0.7140 - val_accuracy: 0.8935\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1390 - accuracy: 0.9496 - val_loss: 0.7053 - val_accuracy: 0.8902\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1400 - accuracy: 0.9499 - val_loss: 0.6526 - val_accuracy: 0.8900\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1362 - accuracy: 0.9503 - val_loss: 0.7278 - val_accuracy: 0.8786\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1324 - accuracy: 0.9528 - val_loss: 0.8516 - val_accuracy: 0.8806\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1331 - accuracy: 0.9516 - val_loss: 0.7833 - val_accuracy: 0.8910\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1331 - accuracy: 0.9514 - val_loss: 0.7560 - val_accuracy: 0.8900\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1278 - accuracy: 0.9535 - val_loss: 0.7596 - val_accuracy: 0.8814\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1319 - accuracy: 0.9531 - val_loss: 0.9020 - val_accuracy: 0.8804\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1270 - accuracy: 0.9546 - val_loss: 0.7955 - val_accuracy: 0.8940\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1270 - accuracy: 0.9546 - val_loss: 0.9423 - val_accuracy: 0.8909\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1274 - accuracy: 0.9548 - val_loss: 0.8930 - val_accuracy: 0.8935\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1227 - accuracy: 0.9562 - val_loss: 0.8944 - val_accuracy: 0.8884\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1226 - accuracy: 0.9574 - val_loss: 0.8472 - val_accuracy: 0.8890\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1257 - accuracy: 0.9565 - val_loss: 0.8575 - val_accuracy: 0.8862\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1221 - accuracy: 0.9577 - val_loss: 0.9182 - val_accuracy: 0.8857\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1246 - accuracy: 0.9571 - val_loss: 0.8603 - val_accuracy: 0.8949\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1223 - accuracy: 0.9575 - val_loss: 0.9100 - val_accuracy: 0.8959\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1187 - accuracy: 0.9586 - val_loss: 0.9399 - val_accuracy: 0.8935\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1196 - accuracy: 0.9596 - val_loss: 1.1542 - val_accuracy: 0.8849\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1138 - accuracy: 0.9608 - val_loss: 0.8764 - val_accuracy: 0.8895\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1150 - accuracy: 0.9599 - val_loss: 1.2164 - val_accuracy: 0.8760\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1127 - accuracy: 0.9610 - val_loss: 1.0257 - val_accuracy: 0.8932\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1157 - accuracy: 0.9600 - val_loss: 1.0790 - val_accuracy: 0.8853\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1091 - accuracy: 0.9609 - val_loss: 0.9887 - val_accuracy: 0.8917\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.9918 - val_accuracy: 0.8931\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1068 - accuracy: 0.9620 - val_loss: 1.0270 - val_accuracy: 0.8909\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1100 - accuracy: 0.9628 - val_loss: 1.0583 - val_accuracy: 0.8955\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9631 - val_loss: 1.2502 - val_accuracy: 0.8894\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1108 - accuracy: 0.9628 - val_loss: 1.0314 - val_accuracy: 0.8952\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9646 - val_loss: 1.1964 - val_accuracy: 0.8929\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1064 - accuracy: 0.9636 - val_loss: 1.1147 - val_accuracy: 0.8951\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1054 - accuracy: 0.9646 - val_loss: 1.2339 - val_accuracy: 0.8858\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1025 - accuracy: 0.9643 - val_loss: 1.1106 - val_accuracy: 0.8939\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1001 - accuracy: 0.9662 - val_loss: 1.1802 - val_accuracy: 0.8901\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0991 - accuracy: 0.9667 - val_loss: 1.1428 - val_accuracy: 0.8936\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0981 - accuracy: 0.9664 - val_loss: 1.1494 - val_accuracy: 0.8954\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1044 - accuracy: 0.9660 - val_loss: 1.3271 - val_accuracy: 0.8828\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.1004 - accuracy: 0.9654 - val_loss: 1.2543 - val_accuracy: 0.8892\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0976 - accuracy: 0.9666 - val_loss: 1.1856 - val_accuracy: 0.8880\n",
      "Epoch 78/200\n",
      "182/469 [==========>...................] - ETA: 1s - loss: 0.0903 - accuracy: 0.9678"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mfit(x_train,y_train,epochs \u001b[39m=\u001b[39m\u001b[39m200\u001b[39m,batch_size \u001b[39m=\u001b[39m\u001b[39m128\u001b[39m,validation_data\u001b[39m=\u001b[39m(x_test,y_test))\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:925\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    924\u001b[0m   \u001b[39mif\u001b[39;00m without_tracing:\n\u001b[0;32m--> 925\u001b[0m     _frequent_tracing_detector_manager\u001b[39m.\u001b[39;49mcalled_without_tracing(\n\u001b[1;32m    926\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key_for_call_stats)\n\u001b[1;32m    927\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     _frequent_tracing_detector_manager\u001b[39m.\u001b[39mcalled_with_tracing(\n\u001b[1;32m    929\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_for_call_stats, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function,\n\u001b[1;32m    930\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_omit_frequent_tracing_warning)\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:187\u001b[0m, in \u001b[0;36m_FrequentTracingDetectorManager.called_without_tracing\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalled_without_tracing\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    186\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 187\u001b[0m     detector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_detector(key)\n\u001b[1;32m    188\u001b[0m     detector\u001b[39m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[0;32m~/Carla_envi/Car_enviroment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:181\u001b[0m, in \u001b[0;36m_FrequentTracingDetectorManager._get_detector\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_detector\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m--> 181\u001b[0m   \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_detectors:\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detectors[key] \u001b[39m=\u001b[39m _FrequentTracingDetector()\n\u001b[1;32m    183\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detectors[key]\n",
      "File \u001b[0;32m/usr/lib/python3.8/weakref.py:427\u001b[0m, in \u001b[0;36mWeakKeyDictionary.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m wr \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs =200,batch_size =128,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.image_utils import load_img,img_to_array\n",
    "image = load_img(\"image_test/download.jpeg\",target_size=(28,28),color_mode = \"grayscale\")\n",
    "img= img_to_array(image)\n",
    "img = 1-img/255\n",
    "plt.imshow(img)\n",
    "\n",
    "print(y_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "Shirt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tag = np.argmax(model.predict(img),axis=1)\n",
    "print(classnames[tag[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Car_enviroment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc40417d40e2457938e3d78b2a2e0058813177b0c69e12c033c503d15659ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
